{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Cloud Masks, Using a U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sys\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Input, MaxPool2D, UpSampling2D, Concatenate, Conv2DTranspose\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,CSVLogger\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/james/GITHUB/ml_utils')\n",
    "\n",
    "from models import Unet\n",
    "from metrics import dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190904:23:14:24\n"
     ]
    }
   ],
   "source": [
    "date = strftime(\"%Y%m%d:%H:%M:%S\", gmtime())\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"/home/james/GITHUB/Kaggle/data/Clouds/\"\n",
    "models_dir = img_dir + \"models/\"\n",
    "train_dir = img_dir + \"train/\"\n",
    "test_dir = img_dir + \"test/\"\n",
    "labels_file = img_dir + \"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "height=256\n",
    "width=256\n",
    "channels=3\n",
    "\n",
    "batch_size = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are stored in a 204 MB csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22184, 2)\n",
      "(11836, 2)\n"
     ]
    }
   ],
   "source": [
    "labelsdf = pd.read_csv(labels_file)\n",
    "print(labelsdf.shape)\n",
    "labelsdf.dropna(inplace=True)\n",
    "print(labelsdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of the labels is a little messy and hard to use programatically. The label is the form \"filename_cloudtype\".  It will be easier to examine the labels if it is reorganized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>type</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0011165.jpg</td>\n",
       "      <td>Fish</td>\n",
       "      <td>264918 937 266318 937 267718 937 269118 937 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0011165.jpg</td>\n",
       "      <td>Flower</td>\n",
       "      <td>1355565 1002 1356965 1002 1358365 1002 1359765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002be4f.jpg</td>\n",
       "      <td>Fish</td>\n",
       "      <td>233813 878 235213 878 236613 878 238010 881 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002be4f.jpg</td>\n",
       "      <td>Flower</td>\n",
       "      <td>1339279 519 1340679 519 1342079 519 1343479 51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002be4f.jpg</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>67495 350 68895 350 70295 350 71695 350 73095 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename    type                                      EncodedPixels\n",
       "0  0011165.jpg    Fish  264918 937 266318 937 267718 937 269118 937 27...\n",
       "1  0011165.jpg  Flower  1355565 1002 1356965 1002 1358365 1002 1359765...\n",
       "4  002be4f.jpg    Fish  233813 878 235213 878 236613 878 238010 881 23...\n",
       "5  002be4f.jpg  Flower  1339279 519 1340679 519 1342079 519 1343479 51...\n",
       "7  002be4f.jpg   Sugar  67495 350 68895 350 70295 350 71695 350 73095 ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = labelsdf[\"Image_Label\"].str.split(\"_\", n = 1, expand = True) \n",
    "df = pd.DataFrame()\n",
    "df['filename'] = new[0]\n",
    "df['type'] = new[1]\n",
    "df['EncodedPixels'] = labelsdf['EncodedPixels']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_to_mask(rle_string, height, width):\n",
    "    \n",
    "    rows, cols = height, width\n",
    "    \n",
    "    if rle_string == -1:\n",
    "        return np.zeros((height, width))\n",
    "    else:\n",
    "        rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n",
    "        rle_pairs = np.array(rle_numbers).reshape(-1,2)\n",
    "        img = np.zeros(rows*cols, dtype=np.uint8)\n",
    "        for index, length in rle_pairs:\n",
    "            index -= 1\n",
    "            img[index:index+length] = 255\n",
    "        img = img.reshape(cols,rows)\n",
    "        img = img.T\n",
    "        stacked_img = np.stack((img,)*3, axis=-1)\n",
    "        return stacked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'> (256, 256, 3)\n",
      "WARNING:tensorflow:From /home/slow-storage/local/Anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 147584      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 512)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 1024) 9438208     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 1024) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 1024) 0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 256 0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 128 147584      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 128 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 1)  65          conv2d_22[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,031,745\n",
      "Trainable params: 31,031,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shape=(height,width,channels)\n",
    "unet = Unet(shape)\n",
    "model = unet.build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudsImageReader(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self,width,height,batch_size,df):\n",
    "\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(self.df.shape[0]/batch_size)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(0,self.df.shape[0])\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        start = index*self.batch_size\n",
    "        end = (index+1)*self.batch_size\n",
    "\n",
    "        image_placeholders = np.arange(start,end)\n",
    "        \n",
    "        x = np.array([])\n",
    "        x = np.zeros((len(image_placeholders),self.width,self.height,3))\n",
    "\n",
    "        y = np.array([])\n",
    "        y = np.zeros((len(image_placeholders),self.width,self.height,1))\n",
    "\n",
    "\n",
    "        counter = 0\n",
    "        for i in image_placeholders:\n",
    "            \n",
    "            image = cv2.imread(train_dir+df['filename'].iloc[i],1)\n",
    "            \n",
    "            # Create Mask\n",
    "            mask = rle_to_mask(df['EncodedPixels'].iloc[i],image.shape[0],image.shape[1])\n",
    "            \n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Resize Images\n",
    "            image = cv2.resize(image, (self.height,self.width))\n",
    "            mask  = cv2.resize(mask,  (self.height,self.width))\n",
    "            \n",
    "            mask = np.resize(mask,(self.width,self.height,1))\n",
    "            \n",
    "            x[counter] = image/255\n",
    "            y[counter] = mask/255\n",
    "            \n",
    "            counter+=1\n",
    "            \n",
    "        return x,y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=models_dir + date + \"-weights.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor=\"dice_coef\",\n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')\n",
    "\n",
    "csv_logger = CSVLogger(models_dir + date + '-training.log')\n",
    "\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.005,\n",
    "                              patience=6, min_lr=0.001)\n",
    "\n",
    "callbacks_list = [checkpoint,reduce_lr,csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "            optimizer=Adam(1e-4), \n",
    "            loss='binary_crossentropy', \n",
    "            metrics=[dice.dice_coef]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = CloudsImageReader(width,height,batch_size,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/slow-storage/local/Anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/600\n",
      "986/986 [==============================] - 1275s 1s/step - loss: 0.3185 - dice_coef: 0.5947\n",
      "\n",
      "Epoch 00001: dice_coef improved from -inf to 0.59474, saving model to /home/james/GITHUB/Kaggle/data/Clouds/models/20190904:23:14:24-weights.hdf5\n",
      "Epoch 2/600\n",
      "986/986 [==============================] - 1431s 1s/step - loss: 0.3184 - dice_coef: 0.5949\n",
      "\n",
      "Epoch 00002: dice_coef improved from 0.59474 to 0.59486, saving model to /home/james/GITHUB/Kaggle/data/Clouds/models/20190904:23:14:24-weights.hdf5\n",
      "Epoch 3/600\n",
      "986/986 [==============================] - 1312s 1s/step - loss: 0.3195 - dice_coef: 0.5940\n",
      "\n",
      "Epoch 00003: dice_coef did not improve from 0.59486\n",
      "Epoch 4/600\n",
      "986/986 [==============================] - 1268s 1s/step - loss: 0.3192 - dice_coef: 0.5943\n",
      "\n",
      "Epoch 00004: dice_coef did not improve from 0.59486\n",
      "Epoch 5/600\n",
      "986/986 [==============================] - 1259s 1s/step - loss: 0.3179 - dice_coef: 0.5955\n",
      "\n",
      "Epoch 00005: dice_coef improved from 0.59486 to 0.59548, saving model to /home/james/GITHUB/Kaggle/data/Clouds/models/20190904:23:14:24-weights.hdf5\n",
      "Epoch 6/600\n",
      "986/986 [==============================] - 1255s 1s/step - loss: 0.3178 - dice_coef: 0.5955\n",
      "\n",
      "Epoch 00006: dice_coef improved from 0.59548 to 0.59554, saving model to /home/james/GITHUB/Kaggle/data/Clouds/models/20190904:23:14:24-weights.hdf5\n",
      "Epoch 7/600\n",
      "986/986 [==============================] - 1256s 1s/step - loss: 0.3183 - dice_coef: 0.5952\n",
      "\n",
      "Epoch 00007: dice_coef did not improve from 0.59554\n",
      "Epoch 8/600\n",
      "986/986 [==============================] - 1279s 1s/step - loss: 0.3190 - dice_coef: 0.5945\n",
      "\n",
      "Epoch 00008: dice_coef did not improve from 0.59554\n",
      "Epoch 9/600\n",
      "986/986 [==============================] - 1292s 1s/step - loss: 0.3183 - dice_coef: 0.5949\n",
      "\n",
      "Epoch 00009: dice_coef did not improve from 0.59554\n",
      "Epoch 10/600\n",
      "986/986 [==============================] - 1274s 1s/step - loss: 0.3177 - dice_coef: 0.5957\n",
      "\n",
      "Epoch 00010: dice_coef improved from 0.59554 to 0.59567, saving model to /home/james/GITHUB/Kaggle/data/Clouds/models/20190904:23:14:24-weights.hdf5\n",
      "Epoch 11/600\n",
      "986/986 [==============================] - 1253s 1s/step - loss: 0.3179 - dice_coef: 0.5954\n",
      "\n",
      "Epoch 00011: dice_coef did not improve from 0.59567\n",
      "Epoch 12/600\n",
      "986/986 [==============================] - 1252s 1s/step - loss: 0.3182 - dice_coef: 0.5952\n",
      "\n",
      "Epoch 00012: dice_coef did not improve from 0.59567\n",
      "Epoch 13/600\n",
      "986/986 [==============================] - 1253s 1s/step - loss: 0.3180 - dice_coef: 0.5954\n",
      "\n",
      "Epoch 00013: dice_coef did not improve from 0.59567\n",
      "Epoch 14/600\n",
      "986/986 [==============================] - 1252s 1s/step - loss: 0.3178 - dice_coef: 0.5956\n",
      "\n",
      "Epoch 00014: dice_coef did not improve from 0.59567\n",
      "Epoch 15/600\n",
      "986/986 [==============================] - 1254s 1s/step - loss: 0.3176 - dice_coef: 0.5957\n",
      "\n",
      "Epoch 00015: dice_coef improved from 0.59567 to 0.59571, saving model to /home/james/GITHUB/Kaggle/data/Clouds/models/20190904:23:14:24-weights.hdf5\n",
      "Epoch 16/600\n",
      "986/986 [==============================] - 1250s 1s/step - loss: 0.3181 - dice_coef: 0.5953\n",
      "\n",
      "Epoch 00016: dice_coef did not improve from 0.59571\n",
      "Epoch 17/600\n",
      "986/986 [==============================] - 1254s 1s/step - loss: 0.3186 - dice_coef: 0.5948\n",
      "\n",
      "Epoch 00017: dice_coef did not improve from 0.59571\n",
      "Epoch 18/600\n",
      "986/986 [==============================] - 1252s 1s/step - loss: 0.3174 - dice_coef: 0.5960\n",
      "\n",
      "Epoch 00018: dice_coef improved from 0.59571 to 0.59599, saving model to /home/james/GITHUB/Kaggle/data/Clouds/models/20190904:23:14:24-weights.hdf5\n",
      "Epoch 19/600\n",
      "986/986 [==============================] - 1250s 1s/step - loss: 0.3168 - dice_coef: 0.5965\n",
      "\n",
      "Epoch 00019: dice_coef improved from 0.59599 to 0.59654, saving model to /home/james/GITHUB/Kaggle/data/Clouds/models/20190904:23:14:24-weights.hdf5\n",
      "Epoch 20/600\n",
      "986/986 [==============================] - 1250s 1s/step - loss: 0.3171 - dice_coef: 0.5962\n",
      "\n",
      "Epoch 00020: dice_coef did not improve from 0.59654\n",
      "Epoch 21/600\n",
      "986/986 [==============================] - 1253s 1s/step - loss: 0.3180 - dice_coef: 0.5955\n",
      "\n",
      "Epoch 00021: dice_coef did not improve from 0.59654\n",
      "Epoch 22/600\n",
      "986/986 [==============================] - 1255s 1s/step - loss: 0.3191 - dice_coef: 0.5944\n",
      "\n",
      "Epoch 00022: dice_coef did not improve from 0.59654\n",
      "Epoch 23/600\n",
      "986/986 [==============================] - 1253s 1s/step - loss: 0.3174 - dice_coef: 0.5960\n",
      "\n",
      "Epoch 00023: dice_coef did not improve from 0.59654\n",
      "Epoch 24/600\n",
      "986/986 [==============================] - 1254s 1s/step - loss: 0.3165 - dice_coef: 0.5969\n",
      "\n",
      "Epoch 00024: dice_coef improved from 0.59654 to 0.59695, saving model to /home/james/GITHUB/Kaggle/data/Clouds/models/20190904:23:14:24-weights.hdf5\n",
      "Epoch 25/600\n",
      "986/986 [==============================] - 1252s 1s/step - loss: 0.3167 - dice_coef: 0.5968\n",
      "\n",
      "Epoch 00025: dice_coef did not improve from 0.59695\n",
      "Epoch 26/600\n",
      "986/986 [==============================] - 1252s 1s/step - loss: 0.3168 - dice_coef: 0.5966\n",
      "\n",
      "Epoch 00026: dice_coef did not improve from 0.59695\n",
      "Epoch 27/600\n",
      "986/986 [==============================] - 1255s 1s/step - loss: 0.3172 - dice_coef: 0.5964\n",
      "\n",
      "Epoch 00027: dice_coef did not improve from 0.59695\n",
      "Epoch 28/600\n",
      "986/986 [==============================] - 1254s 1s/step - loss: 0.3177 - dice_coef: 0.5958\n",
      "\n",
      "Epoch 00028: dice_coef did not improve from 0.59695\n",
      "Epoch 29/600\n",
      "763/986 [======================>.......] - ETA: 4:44 - loss: 0.3205 - dice_coef: 0.5930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-89:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/slow-storage/local/Anaconda3/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/slow-storage/local/Anaconda3/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/slow-storage/local/Anaconda3/lib/python3.7/multiprocessing/pool.py\", line 412, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/home/slow-storage/local/Anaconda3/lib/python3.7/multiprocessing/pool.py\", line 248, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/slow-storage/local/Anaconda3/lib/python3.7/multiprocessing/pool.py\", line 241, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/slow-storage/local/Anaconda3/lib/python3.7/multiprocessing/process.py\", line 112, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/slow-storage/local/Anaconda3/lib/python3.7/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/slow-storage/local/Anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 20, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/slow-storage/local/Anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 70, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/986 [===========================>..] - ETA: 1:06 - loss: 0.3191 - dice_coef: 0.5939- ETA: 1:39 - loss: 0"
     ]
    }
   ],
   "source": [
    "model.load_weights(models_dir + \"20190903:00:11:38-weights.hdf5\")\n",
    "\n",
    "history = model.fit_generator(train_gen, \n",
    "                    steps_per_epoch=int(df.shape[0]/batch_size), \n",
    "                    epochs=600,\n",
    "                    callbacks=callbacks_list,\n",
    "                    verbose=1,\n",
    "                    max_queue_size=1000,\n",
    "                    #initial_epoch=100,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=3,\n",
    "                    shuffle=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
